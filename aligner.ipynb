{"nbformat":4,"nbformat_minor":5,"metadata":{"notebookPath":"aligner.ipynb","accelerator":"GPU","language_info":{"file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3"},"notebookId":"94bac14d-4e8c-450a-837c-f4a0f5419d01","colab":{"name":"aligner.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"markdown","source":"## Download LJSpeech","metadata":{"cellId":"x99j4ld0gr2qy02y2b6fb","id":"0bcca84b"}},{"cell_type":"code","source":"%pwd","metadata":{"cellId":"w48y03hy0gjr0j23fcxti","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"'/home/jupyter/work/resources'"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"%ls","metadata":{"cellId":"d99oohdy5iig1qdr5ng4qe","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"aligner.ipynb  \u001B[0m\u001B[01;34mdata\u001B[0m/     hw3.ipynb  \u001B[01;34mwaveglow\u001B[0m/\n\u001B[01;34malignments\u001B[0m/    \u001B[01;34mdla_tts\u001B[0m/  \u001B[01;34mmodels\u001B[0m/    waveglow_256channels_universal_v5.pt\n"}],"execution_count":3},{"cell_type":"code","source":"# !wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2","metadata":{"outputId":"2e6f0451-2036-4bc4-937b-d38a72e3c5d9","id":"262cdc28","cellId":"wf5ac1flai2zfknwjov7k","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#!tar -xjf LJSpeech-1.1.tar.bz2","metadata":{"cellId":"ijqji6ebvuigs586l4mgn4","trusted":true},"outputs":[{"output_type":"error","ename":"Unknown instance spec","evalue":"tar","traceback":[]}],"execution_count":2},{"cell_type":"code","source":"%pip install torch","metadata":{"cellId":"3ozvehxmvr0qfddapy45","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.6.0)\nRequirement already satisfied: numpy in /kernel/lib/python3.7/site-packages (from torch) (1.19.4)\nRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch) (0.18.2)\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\nYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\n"}],"execution_count":5},{"cell_type":"code","source":"%pip install librosa","metadata":{"outputId":"b72426f1-cc42-496d-d3af-9ac7ca8bf226","id":"6703f3e3","cellId":"vw5dyacki1lvs55dsqip4","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.0)\nRequirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.1)\nRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\nRequirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\nRequirement already satisfied: decorator>=3.0.0 in /kernel/lib/python3.7/site-packages (from librosa) (5.1.0)\nRequirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\nRequirement already satisfied: numpy>=1.15.0 in /kernel/lib/python3.7/site-packages (from librosa) (1.19.4)\nRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\nRequirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.0)\nRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\nRequirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\nRequirement already satisfied: setuptools in /kernel/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (51.0.0)\nRequirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\nRequirement already satisfied: requests in /kernel/lib/python3.7/site-packages (from pooch>=1.0->librosa) (2.25.1)\nRequirement already satisfied: packaging in /kernel/lib/python3.7/site-packages (from pooch>=1.0->librosa) (20.9)\nRequirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\nRequirement already satisfied: six>=1.3 in /kernel/lib/python3.7/site-packages (from resampy>=0.2.2->librosa) (1.16.0)\nRequirement already satisfied: cffi>=1.0 in /kernel/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa) (1.15.0)\nRequirement already satisfied: pycparser in /kernel/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.21)\nRequirement already satisfied: pyparsing>=2.0.2 in /kernel/lib/python3.7/site-packages (from packaging->pooch>=1.0->librosa) (2.4.7)\nRequirement already satisfied: idna<3,>=2.5 in /kernel/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /kernel/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (1.26.7)\nRequirement already satisfied: chardet<5,>=3.0.2 in /kernel/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (4.0.0)\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\nYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\n"}],"execution_count":6},{"cell_type":"code","source":"%pip install torch==1.10.0+cu111 torchaudio==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html","metadata":{"outputId":"b8f1d4e3-07ff-4422-b3a1-56f0ba28727b","id":"e642b7e2","cellId":"akrq7ncn9sgav77syjued8","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nLooking in links: https://download.pytorch.org/whl/torch_stable.html\nCollecting torch==1.10.0+cu111\n  Downloading https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2137.6 MB)\n\u001B[K     |████████████████████████████████| 2137.6 MB 120 bytes/s \n\u001B[?25hCollecting torchaudio==0.10.0+cu111\n  Downloading https://download.pytorch.org/whl/cu111/torchaudio-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2.9 MB)\n\u001B[K     |████████████████████████████████| 2.9 MB 40.4 MB/s \n\u001B[?25hRequirement already satisfied: typing-extensions in /kernel/lib/python3.7/site-packages (from torch==1.10.0+cu111) (4.0.0)\nInstalling collected packages: torch, torchaudio\n\u001B[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/jupyter/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchvision 0.7.0 requires torch==1.6.0, but you have torch 1.10.0+cu111 which is incompatible.\nmmdet 2.3.0rc0+c6b5ca2 requires Pillow<=6.2.2, but you have pillow 8.4.0 which is incompatible.\nmmdet 2.3.0rc0+c6b5ca2 requires torch==1.6.0, but you have torch 1.10.0+cu111 which is incompatible.\nenot-utils 1.0.2 requires torch==1.6.0, but you have torch 1.10.0+cu111 which is incompatible.\u001B[0m\nSuccessfully installed torch-1.10.0+cu111 torchaudio-0.10.0+cu111\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\nYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\n"}],"execution_count":8},{"cell_type":"markdown","source":"## Featurizer","metadata":{"cellId":"vfdyw8c8b3y1acplwe2g","id":"9f813374"}},{"cell_type":"code","source":"from IPython import display\nfrom dataclasses import dataclass\n\nimport torch\nfrom torch import nn\n\nimport torchaudio\n\nimport librosa\nfrom matplotlib import pyplot as plt\n\n\n@dataclass\nclass MelSpectrogramConfig:\n    sr: int = 22050\n    win_length: int = 1024\n    hop_length: int = 256\n    n_fft: int = 1024\n    f_min: int = 0\n    f_max: int = 8000\n    n_mels: int = 80\n    power: float = 1.0\n\n    # value of melspectrograms if we fed a silence into `MelSpectrogram`\n    pad_value: float = -11.5129251\n\n\nclass MelSpectrogram(nn.Module):\n\n    def __init__(self, config: MelSpectrogramConfig):\n        super(MelSpectrogram, self).__init__()\n\n        self.config = config\n\n        self.mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n            sample_rate=config.sr,\n            win_length=config.win_length,\n            hop_length=config.hop_length,\n            n_fft=config.n_fft,\n            f_min=config.f_min,\n            f_max=config.f_max,\n            n_mels=config.n_mels\n        )\n\n        # The is no way to set power in constructor in 0.5.0 version.\n        self.mel_spectrogram.spectrogram.power = config.power\n\n        # Default `torchaudio` mel basis uses HTK formula. In order to be compatible with WaveGlow\n        # we decided to use Slaney one instead (as well as `librosa` does by default).\n        mel_basis = librosa.filters.mel(\n            sr=config.sr,\n            n_fft=config.n_fft,\n            n_mels=config.n_mels,\n            fmin=config.f_min,\n            fmax=config.f_max\n        ).T\n        self.mel_spectrogram.mel_scale.fb.copy_(torch.tensor(mel_basis))\n\n    def forward(self, audio: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        :param audio: Expected shape is [B, T]\n        :return: Shape is [B, n_mels, T']\n        \"\"\"\n\n        mel = self.mel_spectrogram(audio) \\\n            .clamp_(min=1e-5) \\\n            .log_()\n\n        return mel","metadata":{"id":"1e6ccec6","cellId":"mwloefho1oqc2n8kagnxcm","code_folding":[],"trusted":true},"outputs":[{"output_type":"error","ename":"OSError","evalue":"/home/jupyter/.local/lib/python3.7/site-packages/torch/lib/libtorch_global_deps.so: cannot open shared object file: No such file or directory","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)","\u001B[0;32m<ipython-input-1-8c52a670f01a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mdataclasses\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdataclass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtorch\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    194\u001B[0m     \u001B[0;31m# See Note [Global dependencies]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    195\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mUSE_GLOBAL_DEPS\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 196\u001B[0;31m         \u001B[0m_load_global_deps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    197\u001B[0m     \u001B[0;32mfrom\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m*\u001B[0m  \u001B[0;31m# noqa: F403\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/__init__.py\u001B[0m in \u001B[0;36m_load_global_deps\u001B[0;34m()\u001B[0m\n\u001B[1;32m    147\u001B[0m     \u001B[0mlib_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdirname\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhere\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'lib'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlib_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 149\u001B[0;31m     \u001B[0mctypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCDLL\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlib_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mctypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRTLD_GLOBAL\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    150\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/ctypes/__init__.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001B[0m\n\u001B[1;32m    362\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    363\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mhandle\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 364\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_dlopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    365\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    366\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhandle\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mOSError\u001B[0m: /home/jupyter/.local/lib/python3.7/site-packages/torch/lib/libtorch_global_deps.so: cannot open shared object file: No such file or directory"]}],"execution_count":83},{"cell_type":"code","source":"featurizer = MelSpectrogram(MelSpectrogramConfig())","metadata":{"id":"1eee8037","cellId":"zd94f5tgwgi6zabp75zusr","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"cellId":"u2rvimiy68rnlriwmttw2a","id":"9fd361a1"}},{"cell_type":"markdown","source":"## Dataset","metadata":{"cellId":"jdtigk9zwif1i8i99snvoy","id":"a5827f24"}},{"cell_type":"code","source":"class LJSpeechDataset(torchaudio.datasets.LJSPEECH):\n\n    def __init__(self, root):\n        super().__init__(root=root)\n        self._tokenizer = torchaudio.pipelines.TACOTRON2_GRIFFINLIM_CHAR_LJSPEECH.get_text_processor()\n\n    def __getitem__(self, index: int):\n        waveform, _, _, transcript = super().__getitem__(index)\n        waveforn_length = torch.tensor([waveform.shape[-1]]).int()\n        \n        tokens, token_lengths = self._tokenizer(transcript)\n        \n        return waveform, waveforn_length, transcript, tokens, token_lengths\n    \n    def decode(self, tokens, lengths):\n        result = []\n        for tokens_, length in zip(tokens, lengths):\n            text = \"\".join([\n                self._tokenizer.tokens[token]\n                for token in tokens_[:length]\n            ])\n            result.append(text)\n        return result\n                ","metadata":{"id":"fdf3da2a","cellId":"ehydvciulro92zalra4c2h","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = LJSpeechDataset('.')","metadata":{"id":"3b179b68","cellId":"a84dh7hvk4sllwxom210f","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset[0]","metadata":{"outputId":"dd07c87f-975d-4510-8dad-eac2a55486ca","id":"4f585ec7","cellId":"gnqsd5tkllut7vym13ufvm","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from typing import Tuple, Dict, Optional, List, Union\nfrom itertools import islice\n\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\n\n\n@dataclass\nclass Batch:\n    waveform: torch.Tensor\n    waveforn_length: torch.Tensor\n    transcript: List[str]\n    tokens: torch.Tensor\n    token_lengths: torch.Tensor\n    durations: Optional[torch.Tensor] = None\n        \n    def to(self, device: torch.device) -> 'Batch':\n        raise NotImplementedError\n\n\nclass LJSpeechCollator:\n\n    def __call__(self, instances: List[Tuple]) -> Dict:\n        waveform, waveforn_length, transcript, tokens, token_lengths = list(\n            zip(*instances)\n        )\n\n        waveform = pad_sequence([\n            waveform_[0] for waveform_ in waveform\n        ]).transpose(0, 1)\n        waveforn_length = torch.cat(waveforn_length)\n\n        tokens = pad_sequence([\n            tokens_[0] for tokens_ in tokens\n        ]).transpose(0, 1)\n        token_lengths = torch.cat(token_lengths)\n\n        return Batch(waveform, waveforn_length, transcript, tokens, token_lengths)","metadata":{"id":"fe63cb95","cellId":"v137z714rvqme0t3qr4n","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataloader = DataLoader(LJSpeechDataset('.'), batch_size=3, collate_fn=LJSpeechCollator())","metadata":{"id":"4e451bf0","cellId":"bu9h0bb7h1o2g1xga4ebna","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dummy_batch = list(islice(dataloader, 1))[0]\ndummy_batch","metadata":{"outputId":"aa1d8105-9968-45d7-e1ca-2ae384c2eb18","id":"00ef55ac","cellId":"3pow8lxrgf5gq2h2ejb0gr","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"cellId":"gh92mnm8vvt10vxp6aa090r","id":"38df0f5a"}},{"cell_type":"markdown","source":"## Vocoder","metadata":{"cellId":"hxza7fk3nmfrl8tewmf0t","id":"71aaa2bc"}},{"cell_type":"code","source":"# !git clone https://github.com/NVIDIA/waveglow.git\n# %pip install googledrivedownloader","metadata":{"outputId":"87adbc51-8d7c-43ec-bbf6-5ad8097f3aca","id":"78d424f3","cellId":"brrwt1j7p1ord38t2hf1ap","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from google_drive_downloader import GoogleDriveDownloader as gdd","metadata":{"id":"8461bac1","cellId":"mbyu1bcorysh74y4xumvbp","trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"gdd.download_file_from_google_drive(\n    file_id='1rpK8CzAAirq9sWZhe9nlfvxMF1dRgFbF',\n    dest_path='./waveglow_256channels_universal_v5.pt'\n)","metadata":{"outputId":"75e85f83-aeef-47a1-b3b1-80a690ffa26d","id":"47a84237","cellId":"eeb5hjk417glji4iqib7pa","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":"Downloading 1rpK8CzAAirq9sWZhe9nlfvxMF1dRgFbF into ./waveglow_256channels_universal_v5.pt... Done.\n"}],"execution_count":20},{"cell_type":"code","source":"import warnings\nimport sys\nsys.path.append('waveglow/')\n\nwarnings.filterwarnings('ignore')\n\n\nclass Vocoder(nn.Module):\n\n    def __init__(self):\n        super(Vocoder, self).__init__()\n\n        model = torch.load('waveglow_256channels_universal_v5.pt', map_location='cpu')[\n            'model']\n        self.net = model.remove_weightnorm(model)\n\n    @torch.no_grad()\n    def inference(self, spect: torch.Tensor):\n        spect = self.net.upsample(spect)\n\n        # trim the conv artifacts\n        time_cutoff = self.net.upsample.kernel_size[0] - \\\n            self.net.upsample.stride[0]\n        spect = spect[:, :, :-time_cutoff]\n\n        spect = spect.unfold(2, self.net.n_group, self.net.n_group) \\\n            .permute(0, 2, 1, 3) \\\n            .contiguous() \\\n            .flatten(start_dim=2) \\\n            .transpose(-1, -2)\n\n        # generate prior\n        audio = torch.randn(spect.size(0), self.net.n_remaining_channels, spect.size(-1)) \\\n            .to(spect.device)\n\n        for k in reversed(range(self.net.n_flows)):\n            n_half = int(audio.size(1) / 2)\n            audio_0 = audio[:, :n_half, :]\n            audio_1 = audio[:, n_half:, :]\n\n            output = self.net.WN[k]((audio_0, spect))\n\n            s = output[:, n_half:, :]\n            b = output[:, :n_half, :]\n            audio_1 = (audio_1 - b) / torch.exp(s)\n            audio = torch.cat([audio_0, audio_1], 1)\n\n            audio = self.net.convinv[k](audio, reverse=True)\n\n            if k % self.net.n_early_every == 0 and k > 0:\n                z = torch.randn(\n                    spect.size(0), self.net.n_early_size, spect.size(2),\n                    device=spect.device\n                )\n                audio = torch.cat((z, audio), 1)\n\n        audio = audio.permute(0, 2, 1) \\\n            .contiguous() \\\n            .view(audio.size(0), -1)\n\n        return audio","metadata":{"id":"ad7b870c","cellId":"cdehzp79shkacnhoq8te6i","trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# vocoder = Vocoder().to('cuda').eval()","metadata":{"id":"338d1f3a","cellId":"o7h54hbqnrmj7ksnnl8xs","trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"waveform = dummy_batch.waveform[:1]\nmels = featurizer(waveform).cuda()","metadata":{"cellId":"fqpbnj87zpf2w38ghtk98","id":"2201026b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(mels[0].cpu())","metadata":{"outputId":"aaf0db51-533e-43a4-dbdd-7eee762c6fe8","id":"da692e5a","cellId":"xk1idu6klea2q1tdgktc","colab":{"base_uri":"https://localhost:8080/","height":102}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reconstructed_wav = vocoder.inference(mels).cpu()","metadata":{"cellId":"ebe7e6w1fw51yhphnvqbk1","id":"def0a410"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(reconstructed_wav.squeeze(), label='reconstructed', alpha=.5)\nplt.plot(waveform.squeeze(), label='GT', alpha=.5)\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"outputId":"b71de885-cb26-4b57-93d8-7a9c152fff0b","id":"1d2c99bc","cellId":"hizj99bs6s40nff6n6j877","colab":{"base_uri":"https://localhost:8080/","height":265}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display.display(display.Audio(reconstructed_wav, rate=22050))\ndisplay.display(display.Audio(waveform, rate=22050))","metadata":{"outputId":"59d86d58-94ed-43c1-a8cd-625b78a75891","id":"e6c36cb5","cellId":"wjykvfu56rt4hj65198o","colab":{"base_uri":"https://localhost:8080/","height":133}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"cellId":"a5y2bemtexws3hf25m1zik","id":"7f1acdea"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"cellId":"2ps7mfk9iwththxbcelf99","id":"678ae438"}},{"cell_type":"markdown","source":"## Grapheme Aligner","metadata":{"cellId":"xqste7c1otepo5wv8rqow","id":"cda7fa29"}},{"cell_type":"code","source":"@dataclass\nclass Point:\n    token_index: int\n    time_index: int\n    score: float\n\n\n@dataclass\nclass Segment:\n    label: str\n    start: int\n    end: int\n    score: float\n\n    def __repr__(self):\n        return f\"{self.label}\\t({self.score:4.2f}): [{self.start:5d}, {self.end:5d})\"\n\n    @property\n    def length(self):\n        return self.end - self.start\n\n\nclass GraphemeAligner(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n\n        self._wav2vec2 = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H.get_model()\n        self._labels = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H.get_labels()\n        self._char2index = {c: i for i, c in enumerate(self._labels)}\n        self._unk_index = self._char2index['<unk>']\n        self._resampler = torchaudio.transforms.Resample(\n            orig_freq=MelSpectrogramConfig.sr, new_freq=16_000\n        )\n\n    def _decode_text(self, text):\n        text = text.replace(' ', '|').upper()\n        return torch.tensor([\n            self._char2index.get(char, self._unk_index)\n            for char in text\n        ]).long()\n\n    @torch.no_grad()\n    def forward(\n        self,\n        wavs: torch.Tensor,\n        wav_lengths: torch.Tensor,\n        texts: Union[str, List[str]]\n    ):\n        if isinstance(texts, str):\n            texts = [texts]\n        batch_size = wavs.shape[0]\n\n        durations = []\n        for index in range(batch_size):\n            current_wav = wavs[index, :wav_lengths[index]].unsqueeze(dim=0)\n            current_wav = self._resampler(current_wav)\n            emission, _ = self._wav2vec2(current_wav)\n            emission = emission.log_softmax(dim=-1).squeeze(dim=0).cpu()\n\n            tokens = self._decode_text(texts[index])\n\n            trellis = self._get_trellis(emission, tokens)\n            path = self._backtrack(trellis, emission, tokens)\n            segments = self._merge_repeats(texts[index], path)\n\n            num_frames = emission.shape[0]\n            relative_durations = torch.tensor([\n                segment.length / num_frames for segment in segments\n            ])\n\n            durations.append(relative_durations)\n            \n        durations = pad_sequence(durations).transpose(0, 1)\n        return durations\n\n    def _get_trellis(self, emission, tokens, blank_id=0):\n        num_frame = emission.size(0)\n        num_tokens = len(tokens)\n\n        # Trellis has extra dimension for both time axis and tokens.\n        # The extra dim for tokens represents <SoS> (start-of-sentence)\n        # The extra dim for time axis is for simplification of the code.\n        trellis = torch.full((num_frame + 1, num_tokens + 1), -float('inf'))\n        trellis[:, 0] = 0\n        for t in range(num_frame):\n            trellis[t + 1, 1:] = torch.maximum(\n                # Score for staying at the same token\n                trellis[t, 1:] + emission[t, blank_id],\n\n                # Score for changing to the next token\n                trellis[t, :-1] + emission[t, tokens],\n            )\n        return trellis\n\n    def _backtrack(self, trellis, emission, tokens, blank_id=0):\n        # Note:\n        # j and t are indices for trellis, which has extra dimensions\n        # for time and tokens at the beginning.\n        # When refering to time frame index `T` in trellis,\n        # the corresponding index in emission is `T-1`.\n        # Similarly, when refering to token index `J` in trellis,\n        # the corresponding index in transcript is `J-1`.\n        j = trellis.size(1) - 1\n        t_start = torch.argmax(trellis[:, j]).item()\n\n        path = []\n        for t in range(t_start, 0, -1):\n            # 1. Figure out if the current position was stay or change\n            # Note (again):\n            # `emission[J-1]` is the emission at time frame `J` of trellis dimension.\n            # Score for token staying the same from time frame J-1 to T.\n            stayed = trellis[t - 1, j] + emission[t - 1, blank_id]\n            # Score for token changing from C-1 at T-1 to J at T.\n            changed = trellis[t - 1, j - 1] + emission[t - 1, tokens[j - 1]]\n\n            # 2. Store the path with frame-wise probability.\n            prob = emission[t - 1, tokens[j - 1]\n                            if changed > stayed else 0].exp().item()\n            # Return token index and time index in non-trellis coordinate.\n            path.append(Point(j - 1, t - 1, prob))\n\n            # 3. Update the token\n            if changed > stayed:\n                j -= 1\n                if j == 0:\n                    break\n\n        else:\n            raise ValueError('Failed to align')\n\n        return path[::-1]\n\n    def _merge_repeats(self, text, path):\n        i1, i2 = 0, 0\n        segments = []\n        while i1 < len(path):\n            while i2 < len(path) and path[i1].token_index == path[i2].token_index:\n                i2 += 1\n            score = sum(path[k].score for k in range(i1, i2)) / (i2 - i1)\n            segments.append(\n                Segment(\n                    text[path[i1].token_index],\n                    path[i1].time_index,\n                    path[i2 - 1].time_index + 1,\n                    score\n                )\n            )\n            i1 = i2\n\n        return segments\n\n    @staticmethod\n    def plot_trellis_with_path(trellis, path):\n        # to plot trellis with path, we take advantage of 'nan' value\n        trellis_with_path = trellis.clone()\n        for i, p in enumerate(path):\n            trellis_with_path[p.time_index, p.token_index] = float('nan')\n        plt.imshow(trellis_with_path[1:, 1:].T, origin='lower')","metadata":{"id":"5646a993","cellId":"5beivf187l402ac1h258x5j","code_folding":[43,75,94,132]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda:0')\naligner = GraphemeAligner().to(device)","metadata":{"cellId":"69r53zwi82s4iamp47m37w","id":"5d58d4ed"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dummy_batch","metadata":{"outputId":"38f8d363-ab06-4b1a-8a54-baaa7780e67b","id":"a2ed4225","cellId":"3mvowjhpw7s5qpxfpm0yk9","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dummy_batch.durations = aligner(\n    dummy_batch.waveform.to(device), dummy_batch.waveforn_length, dummy_batch.transcript\n)","metadata":{"cellId":"2ynqt2ql4flmg0vv9sul8","id":"10d055b0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dummy_batch","metadata":{"outputId":"748e2a2c-dc8e-48d5-dbe8-48f373548e20","id":"6de9923a","cellId":"l8fpb73iuwrk3q9pkyi0bc","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualize","metadata":{"cellId":"5bsbjrv44cfpxvj9t4ii6","id":"7999a27f"}},{"cell_type":"code","source":"","metadata":{"cellId":"nbpmvrj9pyo7idmleoqz9","id":"6b3681dd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"index = 0\n\nwaveform = dummy_batch.waveform[index][:dummy_batch.waveforn_length[index]]\ndurations = dummy_batch.durations[index][:dummy_batch.token_lengths[index]]\n\n# scale by waveform domain\ndurations = durations * dummy_batch.waveforn_length[index]\ndurations = durations.cumsum(dim=0).int()\n\nprint(dummy_batch.transcript[index])\nleft = 0\nfor right, char in zip(durations[:10], dummy_batch.transcript[index]):\n    print(char)\n    display.display(display.Audio(waveform[left:right], rate=22050))\n    left = right\n    print('-' * 99)","metadata":{"outputId":"ac41dde5-30e2-4fa6-a6bb-34b7253b05cc","id":"c4fecf87","cellId":"zu485vurinkecxkyxuy4cn","colab":{"base_uri":"https://localhost:8080/","height":995}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dummy_batch","metadata":{"outputId":"16e66718-5b0c-4f62-a739-71602e612ddd","id":"95359757","cellId":"e5rmx8so0dm9so5lg8vpt5","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/MatyashDare/dla_tts\n    ","metadata":{"id":"687a60fb","cellId":"u7gfinxa11c4wcxozo21ny","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"cellId":"59najvpel1eikh1kz6hjxi"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!:bash\n#pragma dataset init LJSpeech-1.1 --size 7Gb\n\nset -e\ncd /home/jupyter/mnt/datasets/LJSpeech-1.1\nwget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\ntar -xvf LJSpeech-1.1.tar.bz2\nrm -rf LJSpeech-1.1.tar.bz2","metadata":{"jupyter":{"outputs_hidden":true},"cellId":"0yanoqx0t45jf7nxwvxjx","trusted":true,"collapsed":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"#%pip install wandb","metadata":{"cellId":"i9t787xsma2c76q5f9ti7","trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#!g1.1\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nimport torchaudio\nimport os\nimport librosa\nimport wandb\nfrom tqdm import tqdm\nfrom dataclasses import dataclass\nfrom data.data_preprocessing import LJSpeechDataset, LJSpeechCollator\nfrom models.model import FastSpeechModel","metadata":{"cellId":"8ms9bu9lzg6doqrul82prb","trusted":true},"outputs":[],"execution_count":84},{"cell_type":"code","source":"#!g1.1\nimport warnings\nimport sys\nsys.path.append('waveglow/')\n\nwarnings.filterwarnings('ignore')\n\n\nclass Vocoder(nn.Module):\n\n    def __init__(self):\n        super(Vocoder, self).__init__()\n\n        model = torch.load('waveglow_256channels_universal_v5.pt', map_location='cpu')[\n            'model']\n        self.net = model.remove_weightnorm(model)\n\n    @torch.no_grad()\n    def inference(self, spect: torch.Tensor):\n        spect = self.net.upsample(spect)\n\n        \n        \n        # trim the conv artifacts\n        time_cutoff = self.net.upsample.kernel_size[0] - \\\n            self.net.upsample.stride[0]\n        spect = spect[:, :, :-time_cutoff]\n\n        spect = spect.unfold(2, self.net.n_group, self.net.n_group) \\\n            .permute(0, 2, 1, 3) \\\n            .contiguous() \\\n            .flatten(start_dim=2) \\\n            .transpose(-1, -2)\n\n        # generate prior\n        audio = torch.randn(spect.size(0), self.net.n_remaining_channels, spect.size(-1)) \\\n            .to(spect.device)\n\n        for k in reversed(range(self.net.n_flows)):\n            n_half = int(audio.size(1) / 2)\n            audio_0 = audio[:, :n_half, :]\n            audio_1 = audio[:, n_half:, :]\n\n            output = self.net.WN[k]((audio_0, spect))\n\n            s = output[:, n_half:, :]\n            b = output[:, :n_half, :]\n            audio_1 = (audio_1 - b) / torch.exp(s)\n            audio = torch.cat([audio_0, audio_1], 1)\n\n            audio = self.net.convinv[k](audio, reverse=True)\n\n            if k % self.net.n_early_every == 0 and k > 0:\n                z = torch.randn(\n                    spect.size(0), self.net.n_early_size, spect.size(2),\n                    device=spect.device\n                )\n                audio = torch.cat((z, audio), 1)\n\n        audio = audio.permute(0, 2, 1) \\\n            .contiguous() \\\n            .view(audio.size(0), -1)\n\n        return audio\n","metadata":{"cellId":"tkkzbv9kxgdefcigzxq0q","trusted":true},"outputs":[],"execution_count":85},{"cell_type":"code","source":"#!g1.1\nvocoder = Vocoder().to('cuda').eval()","metadata":{"cellId":"rhlgj0o8ys4nk45nko3iq","trusted":true},"outputs":[],"execution_count":86},{"cell_type":"code","source":"#!g1.1\ndef train(run, epoch, train_dataloader, model, optimizer, scheduler, log_loss_every, log_audio_every):\n    model.train()\n    i = 0\n    for batch in tqdm(train_dataloader):\n        pred_mel, pred_len = model(batch)\n\n        mask = (torch.arange(pred_len.shape[1])[None, :].to(device)  <= batch['token_lengths'][:, None]).float()\n        loss_len = criterion(pred_len * mask,  torch.log1p(batch[\"duration_multipliers\"]) * mask)\n\n        mask = (torch.arange(pred_mel.shape[1])[None, :].to(device)  <= batch['melspec_length'][:, None]).float()\n        loss_mel = criterion(pred_mel * mask[:, :, None], batch['melspec'] * mask[:, :, None])\n        loss = loss_mel + loss_len\n        if i % log_loss_every == 0 and i != 0:\n            run.log({\"Total loss\" : loss}, step=epoch * len(train_dataloader) + i)\n            run.log({\"Melspec Loss\" : loss_mel}, step=epoch * len(train_dataloader) + i)\n            run.log({\"Duration Loss\" : loss_len}, step=epoch * len(train_dataloader) + i)\n\n        if i % log_audio_every == 0 and i != 0:\n            mel_to_log = pred_mel[0]\n            melspec_to_log  = pred_mel[0][:, :batch['melspec_length'][0]].unsqueeze(0)\n            reconstructed_wav = vocoder.inference(melspec_to_log).squeeze().detach().cpu().numpy()\n            run.log({\"Audio Train\" : wandb.Audio(reconstructed_wav, 22050)}, step=epoch * len(train_dataloader) + i)\n            d = (torch.exp(pred_len[0]) - 1).round().int()\n            d[d < 1] = 1\n            d1 = d.cumsum(0)\n            maxlen = d.sum().item()\n            mask1 = torch.arange(maxlen)[None, :].to(device) < (d1[:, None])\n            mask2 = torch.arange(maxlen)[None, :].to(device) >= (d1 - d)[:, None]\n            mask = (mask2 * mask1).float()\n            run.log({\"`Durations predicted\" : wandb.Image(mask.detach().cpu().numpy())}, step=epoch * len(train_dataloader) + i)\n            d = batch['duration_multipliers'][0]\n            d1 = d.cumsum(0)\n            maxlen = d.sum().item()\n            mask1 = torch.arange(maxlen)[None, :].to(device) < (d1[:, None])\n            mask2 = torch.arange(maxlen)[None, :].to(device) >= (d1 - d)[:, None]\n            mask = (mask2 * mask1).float()\n            run.log({\"Durations true\" : wandb.Image(mask.detach().cpu().numpy())}, step=epoch * len(train_dataloader) + i)\n        optimizer.zero_grad()\n        loss.backward()\n#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n        optimizer.step()\n        scheduler.step()\n        i += 1\n\n\ndef validation(run, iteration, model):\n    model.eval()\n    tokenizer  = torchaudio.pipelines.TACOTRON2_GRIFFINLIM_CHAR_LJSPEECH.get_text_processor()\n    sentences = ['A defibrillator is a device that gives a high energy electric shock to the heart of someone who is in cardiac arrest',\n                 'Massachusetts Institute of Technology may be best known for its math, science and engineering education',\n                 'Wasserstein distance or Kantorovich Rubinstein metric is a distance function defined between probability distributions on a given metric space']\n    print(\"Validation:\")\n    audios = []\n    durations = []\n    for k, sentence in enumerate(sentences):\n        tokens, length = tokenizer(sentence.lower())\n        batch = {}\n        batch['tokens'], batch['token_lengths'] = tokens.to(device), length.to(device)\n        pred_mel, pred_len = model(batch, False)\n        reconstructed_wav = vocoder.inference(pred_mel).squeeze().detach().cpu().numpy()\n        d = (torch.exp(pred_len[0]) - 1).round().int()\n        d[d < 1] = 1\n        d1 = d.cumsum(0)\n        maxlen = d.sum().item()\n        mask1 = torch.arange(maxlen)[None, :].to(device) < (d1[:, None])\n        mask2 = torch.arange(maxlen)[None, :].to(device) >= (d1 - d)[:, None]\n        mask = (mask2 * mask1).float()\n        audios.append(wandb.Audio(reconstructed_wav, 22050, caption=sentence))\n        durations.append(wandb.Image(mask.detach().cpu().numpy(), caption=sentence))\n    run.log({\"Audio validation\" : audios}, step=iteration)\n\n\nif __name__ == '__main__':\n    project_name = 'tts_total'\n    name = 'FastSpeechAlignments'\n    log_audio_every = 100\n    log_loss_every = 5\n    n_epochs = 100\n    batch_size = 16\n    device = 'cuda'\n    train_dataloader = DataLoader(LJSpeechDataset('/home/jupyter/mnt/datasets/LJSpeech-1.1/'),\n                                  batch_size=batch_size,\n                                  collate_fn=LJSpeechCollator(device),\n                                  shuffle=True)\n    model = FastSpeechModel(vocab_size=38,\n                            max_len=10000,\n                            n_layers=6,\n                            output_size=80,\n                            model_size=256,\n                            inter_size=1024,\n                            inter_kernel_size=(9, 1),\n                            head_num=2,\n                            size_head=128,\n                            p=0.1,\n                            device=device).to(device)\n    vocoder = Vocoder().eval().to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-6)\n    scheduler = optim.lr_scheduler.OneCycleLR(optimizer,\n                                              1e-4,\n                                              total_steps=n_epochs * len(train_dataloader),\n                                              div_factor=1e+4,\n                                              pct_start=0.05,\n                                              anneal_strategy='linear')\n\n    with wandb.init(project=project_name, name=name) as run:\n        for i in range(n_epochs):\n            print(f'Start Epoch {i}')\n            train(run, i, train_dataloader, model, optimizer, scheduler, log_loss_every, log_audio_every)\n            validation(run, (i + 1) * len(train_dataloader), model)","metadata":{"cellId":"zfbtfvtlwji4pwenxfn0s","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    Syncing run <strong><a href=\"https://wandb.ai/matyashpr/tts_total/runs/1kc25osf\" target=\"_blank\">FastSpeechAlignments</a></strong> to <a href=\"https://wandb.ai/matyashpr/tts_total\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "},"metadata":{}},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":""},{"output_type":"stream","name":"stdout","text":""},{"output_type":"stream","name":"stderr","text":" 49%|████▉     | 405/819 [01:46<01:49,  3.79it/s]\n"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 17719... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 273.36MB of 273.36MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.9999939…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2721a4ad46141f197aae5f0601d137e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Duration Loss</td><td>█▆▆▅▅▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Melspec Loss</td><td>█▄▄▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Total loss</td><td>█▅▄▃▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Duration Loss</td><td>0.01938</td></tr><tr><td>Melspec Loss</td><td>0.28288</td></tr><tr><td>Total loss</td><td>0.30226</td></tr></table>\n</div></div>\nSynced 5 W&B file(s), 2306 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">FastSpeechAlignments</strong>: <a href=\"https://wandb.ai/matyashpr/tts_total/runs/1kc25osf\" target=\"_blank\">https://wandb.ai/matyashpr/tts_total/runs/1kc25osf</a><br/>\nFind logs at: <code>./wandb/run-20211208_111634-1kc25osf/logs</code><br/>\n"},"metadata":{}},{"output_type":"error","ename":"OSError","evalue":"[Errno 28] No space left on device","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)","\u001B[0;32m/usr/lib/python3.7/shutil.py\u001B[0m in \u001B[0;36mmove\u001B[0;34m(src, dst, copy_function)\u001B[0m\n\u001B[1;32m    565\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 566\u001B[0;31m         \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrename\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreal_dst\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    567\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mOSError\u001B[0m: [Errno 18] Invalid cross-device link: '/tmp/tmp_bceq0rkwandb-media/3pnwr1on.wav' -> '/home/jupyter/work/resources/wandb/run-20211208_111634-1kc25osf/files/media/audio/Audio Train_70015_a9b97af6bf46aa556aea.wav'","\nDuring handling of the above exception, another exception occurred:\n","\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)","\u001B[0;32m<ipython-input-4-ba01ce10977f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    102\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_epochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'Start Epoch {i}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 104\u001B[0;31m             \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_dataloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscheduler\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlog_loss_every\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlog_audio_every\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    105\u001B[0m \u001B[0;31m#             if i % save_every == 0:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m \u001B[0;31m#                 torch.save(model.state_dict(), f\"{experiment_path}/model.pth\")\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m<ipython-input-4-ba01ce10977f>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(run, epoch, train_dataloader, model, optimizer, scheduler, log_loss_every, log_audio_every)\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss_mel\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mloss_len\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mi\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mlog_loss_every\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mi\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m             \u001B[0mrun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m\"Total loss\"\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mepoch\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dataloader\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m             \u001B[0mrun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m\"Melspec Loss\"\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0mloss_mel\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mepoch\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dataloader\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m             \u001B[0mrun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m\"Duration Loss\"\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0mloss_len\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mepoch\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dataloader\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001B[0m in \u001B[0;36mlog\u001B[0;34m(self, data, step, commit, sync)\u001B[0m\n\u001B[1;32m   1338\u001B[0m                 \u001B[0;32mreturn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1339\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mstep\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_step\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1340\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_flush\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1341\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1342\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mcommit\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/wandb/sdk/wandb_history.py\u001B[0m in \u001B[0;36m_flush\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     57\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"_timestamp\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"_timestamp\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_callback\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_callback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_step\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     60\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\u001B[0m in \u001B[0;36m_history_callback\u001B[0;34m(self, row, step)\u001B[0m\n\u001B[1;32m   1022\u001B[0m             \u001B[0mnot_using_tensorboard\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwandb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpatched\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"tensorboard\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1023\u001B[0m             self._backend.interface.publish_history(\n\u001B[0;32m-> 1024\u001B[0;31m                 \u001B[0mrow\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpublish_step\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnot_using_tensorboard\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1025\u001B[0m             )\n\u001B[1;32m   1026\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\u001B[0m in \u001B[0;36mpublish_history\u001B[0;34m(self, data, step, run, publish_step)\u001B[0m\n\u001B[1;32m    489\u001B[0m     ) -> None:\n\u001B[1;32m    490\u001B[0m         \u001B[0mrun\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrun\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 491\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata_types\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhistory_dict_to_json\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    492\u001B[0m         \u001B[0mhistory\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mHistoryRecord\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    493\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mpublish_step\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/wandb/sdk/data_types.py\u001B[0m in \u001B[0;36mhistory_dict_to_json\u001B[0;34m(run, payload, step)\u001B[0m\n\u001B[1;32m   2587\u001B[0m             \u001B[0mpayload\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhistory_dict_to_json\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2588\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2589\u001B[0;31m             \u001B[0mpayload\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mval_to_json\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnamespace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2590\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2591\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mpayload\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/wandb/sdk/data_types.py\u001B[0m in \u001B[0;36mval_to_json\u001B[0;34m(run, key, val, namespace)\u001B[0m\n\u001B[1;32m   2667\u001B[0m                 \u001B[0;32mand\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_log_type\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"partitioned-table\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"joined-table\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2668\u001B[0m             ):\n\u001B[0;32m-> 2669\u001B[0;31m                 \u001B[0mval\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbind_to_run\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnamespace\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2670\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2671\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_json\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/wandb/data_types.py\u001B[0m in \u001B[0;36mbind_to_run\u001B[0;34m(self, run, key, step, id_)\u001B[0m\n\u001B[1;32m   1006\u001B[0m             )\n\u001B[1;32m   1007\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1008\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mAudio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbind_to_run\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mid_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1009\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1010\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mto_json\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrun\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/wandb/sdk/data_types.py\u001B[0m in \u001B[0;36mbind_to_run\u001B[0;34m(self, run, key, step, id_)\u001B[0m\n\u001B[1;32m    527\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    528\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_is_tmp\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 529\u001B[0;31m             \u001B[0mshutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmove\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    530\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnew_path\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    531\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_is_tmp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/shutil.py\u001B[0m in \u001B[0;36mmove\u001B[0;34m(src, dst, copy_function)\u001B[0m\n\u001B[1;32m    578\u001B[0m             \u001B[0mrmtree\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    579\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 580\u001B[0;31m             \u001B[0mcopy_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreal_dst\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    581\u001B[0m             \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munlink\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    582\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mreal_dst\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/shutil.py\u001B[0m in \u001B[0;36mcopy2\u001B[0;34m(src, dst, follow_symlinks)\u001B[0m\n\u001B[1;32m    264\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdst\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    265\u001B[0m         \u001B[0mdst\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdst\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbasename\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 266\u001B[0;31m     \u001B[0mcopyfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdst\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfollow_symlinks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfollow_symlinks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    267\u001B[0m     \u001B[0mcopystat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdst\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfollow_symlinks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfollow_symlinks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    268\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdst\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/shutil.py\u001B[0m in \u001B[0;36mcopyfile\u001B[0;34m(src, dst, follow_symlinks)\u001B[0m\n\u001B[1;32m    120\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfsrc\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    121\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdst\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'wb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfdst\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 122\u001B[0;31m                 \u001B[0mcopyfileobj\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfsrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfdst\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    123\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdst\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mOSError\u001B[0m: [Errno 28] No space left on device"]}],"execution_count":87},{"cell_type":"code","source":"#!g1.1\n","metadata":{"cellId":"6nax0t9f5br7q2bn4euvja"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"cellId":"079u3vj05o05bw3h3jwpa4o"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"cellId":"lbtnnokfn0hn9s7yfh1wr"},"outputs":[],"execution_count":null}]}